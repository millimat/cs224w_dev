{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn.linear_model, sklearn.ensemble, sklearn.model_selection \n",
    "import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "np.random.seed(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srname_to_class = {}\n",
    "for (i,line) in enumerate(open('output/srurls_to_names.txt')):\n",
    "    url = line.strip().split()[0]\n",
    "    srname = url[3:-1] # e.g. '/r/politics/' to 'politics'\n",
    "    srname_to_class[srname] = np.float64(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_basic_language = np.genfromtxt('output/basic_and_language_nodelete.tsv', delimiter='\\t', skip_header=1,\n",
    "                                   converters = {2: lambda name: srname_to_class[name]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_ids = [line.strip().split('\\t')[1] for line in open('output/basic_and_language_nodelete.tsv').readlines()[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = data_basic_language.shape[0]\n",
    "idx = np.array(range(m), dtype=int)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "data_basic_language = data_basic_language[idx,:]\n",
    "\n",
    "# Create training and test set\n",
    "trainprop = 0.95\n",
    "trainstop = int(m * trainprop)\n",
    "\n",
    "# ignore gold column at end and post id/user id columns at beginning\n",
    "trainset = data_basic_language[:trainstop]\n",
    "trainX = trainset[:,2:-2] \n",
    "trainY = trainset[:,-2]\n",
    "\n",
    "testset = data_basic_language[trainstop:]\n",
    "testX = testset[:,2:-2]\n",
    "testY = testset[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainsizes = np.array(np.linspace(0, trainstop, 21)[1:], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first baseline model, we'll just make predictions using the overall mean sore from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainerrs = []\n",
    "testerrs = []\n",
    "\n",
    "for s in trainsizes:\n",
    "    print(s)\n",
    "    Xtr = trainX[:s,:]\n",
    "    Ytr = trainY[:s]\n",
    "    full_mean = np.mean(Ytr)\n",
    "    \n",
    "    trainerrs.append(np.mean((full_mean - Ytr)**2))\n",
    "    testerrs.append(np.mean((full_mean-testY)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(trainsizes, trainerrs, label='Train err')\n",
    "plt.plot(trainsizes, testerrs, label='Test err')\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Mean-only')\n",
    "plt.legend()\n",
    "plt.savefig('plots/mean_only.eps', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll track the average deviation of post score from the overall mean for each user, each hour, each day of the week, and each subreddit. Each prediction will be the overall mean plus the sum of mean deviations for each relevant feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainerrs = []\n",
    "testerrs = []\n",
    "\n",
    "def get_day(x):\n",
    "    return [j for (j, d) in enumerate(x[1:8]) if d == 1][0]\n",
    "\n",
    "def get_hour(x):\n",
    "    return [j for (j, h) in enumerate(x[8:32]) if h == 1][0]\n",
    "\n",
    "for s in trainsizes:\n",
    "    print(s)\n",
    "    Xtr = trainX[:s,:]\n",
    "    Ytr = trainY[:s]\n",
    "    full_mean = np.mean(Ytr)\n",
    "    \n",
    "    user_devs = defaultdict(list)\n",
    "    sr_devs = defaultdict(list)\n",
    "    day_devs = defaultdict(list)\n",
    "    hour_devs = defaultdict(list)\n",
    "    \n",
    "    # Get deviation lists\n",
    "    for (i,x) in enumerate(Xtr):\n",
    "        dev = Ytr[i] - full_mean\n",
    "        user_devs[user_ids[idx[i]]].append(dev)\n",
    "\n",
    "        subreddit = x[0]\n",
    "        sr_devs[subreddit].append(dev)\n",
    "        \n",
    "        day = get_day(x)\n",
    "        day_devs[day].append(dev)\n",
    "        \n",
    "        hour = get_hour(x)\n",
    "        hour_devs[hour].append(dev)\n",
    "        \n",
    "    # Take means of lists\n",
    "    user_dev_means = {k: np.mean(v) for (k,v) in user_devs.iteritems()}\n",
    "    sr_dev_means = {k: np.mean(v) for (k,v) in sr_devs.iteritems()}\n",
    "    day_dev_means = {k: np.mean(v) for (k,v) in day_devs.iteritems()}\n",
    "    hour_dev_means = {k: np.mean(v) for (k,v) in hour_devs.iteritems()}\n",
    "    \n",
    "    # Make prediction as y = full_mean + (mean devs for user, hour, sr, day)\n",
    "    train_prediction = np.zeros(s)\n",
    "    for (i, x) in enumerate(Xtr):\n",
    "        prediction = full_mean + user_dev_means[user_ids[idx[i]]]\\\n",
    "                     + sr_dev_means[x[0]] + day_dev_means[get_day(x)]\\\n",
    "                     + hour_dev_means[get_hour(x)]\n",
    "        train_prediction[i] = prediction\n",
    "\n",
    "    test_prediction = np.zeros(testY.size)\n",
    "    for (i, x) in enumerate(testX):\n",
    "        uid = user_ids[idx[i+trainstop]]\n",
    "        prediction = full_mean + user_dev_means.get(uid,0) + sr_dev_means.get(uid,0)\\\n",
    "                     + day_dev_means.get(get_day(x),0) + hour_dev_means.get(get_hour(x),0)\n",
    "        test_prediction[i] = prediction\n",
    "        \n",
    "    trainerrs.append(np.mean((train_prediction - Ytr)**2))\n",
    "    testerrs.append(np.mean((test_prediction - testY)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(trainsizes, trainerrs, label='Train err')\n",
    "plt.plot(trainsizes, testerrs, label='Test err')\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Means and deviations')\n",
    "plt.legend()\n",
    "plt.savefig('plots/mean_and_deviations.eps', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll try out a linear model using lasso regression with cross-validation to select regularization strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainerrs = []\n",
    "testerrs = []\n",
    "\n",
    "for s in trainsizes:\n",
    "    print(s)\n",
    "    Xtr = trainX[:s,:]\n",
    "    Ytr = trainY[:s]\n",
    "    \n",
    "    lasso_model = sklearn.linear_model.LassoCV(n_jobs=-1)\n",
    "    lasso_model.fit(Xtr, Ytr)\n",
    "    trainerrs.append(np.mean((lasso_model.predict(Xtr) - Ytr)**2))\n",
    "    testerrs.append(np.mean((lasso_model.predict(testX) - testY)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(trainsizes, trainerrs, label='Train err')\n",
    "plt.plot(trainsizes, testerrs, label='Test err')\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Lasso')\n",
    "plt.legend()\n",
    "plt.savefig('plots/basic_language_lasso.eps', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a random forest regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainerrs = []\n",
    "testerrs = []\n",
    "\n",
    "for s in trainsizes:\n",
    "    print(s)\n",
    "    Xtr = trainX[:s,:]\n",
    "    Ytr = trainY[:s]\n",
    "    \n",
    "    rfmodel = sklearn.ensemble.RandomForestRegressor(n_jobs=-1, max_features='auto', max_depth=10)\n",
    "    rfmodel.fit(Xtr, Ytr)\n",
    "    trainerrs.append(np.mean((rfmodel.predict(Xtr) - Ytr)**2))\n",
    "    testerrs.append(np.mean((rfmodel.predict(testX) - testY)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(trainsizes, trainerrs, label='Train err')\n",
    "plt.plot(trainsizes, testerrs, label='Test err')\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Random forest')\n",
    "plt.legend()\n",
    "plt.savefig('plots/basic_language_randforest.eps', format='eps', dpi=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
